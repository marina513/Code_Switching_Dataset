{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"yellow\">Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import re,os\n",
    "import string\n",
    "eng_char = string.ascii_lowercase\n",
    "\n",
    "name = \"LM\"\n",
    "with open(name + '/data_all_final.txt') as f:\n",
    "    data_all_final = f.readlines()\n",
    "\n",
    "\n",
    "ars_LM = []; ens_LM = []\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#Read  0 - 9\n",
    "with open('LM/words_en_ar_after_filter_0_9.txt') as f:\n",
    "    words_0_9  = f.readlines()\n",
    "for i in range(len(words_0_9)):\n",
    "    ar  =  ''\n",
    "    word = words_0_9[i]\n",
    "    for a in range(len(word)):\n",
    "        if(word[a].lower() in eng_char):\n",
    "            break\n",
    "        ar = ar + word[a]\n",
    "\n",
    "    ar = ar.strip()\n",
    "    en  = word[a:].replace('\\n','').strip()\n",
    "\n",
    "    if(ar not in ars_LM):\n",
    "        ars_LM.append(ar) ; ens_LM.append(en)\n",
    "\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#Read  9 - 18\n",
    "with open('LM/words_en_ar_after_filter_9_18.txt') as f:\n",
    "    words_9_18 = f.readlines()\n",
    "\n",
    "for i in range(len(words_9_18)):\n",
    "    s = words_9_18[i]\n",
    "    if((s[:s.find(\"-->\")].strip()) not in ars_LM):\n",
    "        ars_LM.append(s[:s.find(\"-->\")].strip())\n",
    "        ens_LM.append(s[s.find(\"-->\")+3:].strip())\n",
    "\n",
    "ars_LM[ars_LM.index('')] = \"SPACE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"LM/words_en_ar_after_filter_ALL.txt\", \"w\")\n",
    "for e in range(len(ars_LM)):\n",
    "    textfile.write(ars_LM[e] + \"  -->  \" + ens_LM[e] + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"yellow\"> ------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"yellow\">GOML  ðŸ’ƒðŸ’ƒðŸ’ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1418/37314023 [02:58<1345:19:42,  7.70it/s]"
     ]
    }
   ],
   "source": [
    "data_all_final_filtered = [] ; data_all_final_filtered_asle = []\n",
    "found = False\n",
    "for i in tqdm(range(0,len(data_all_final))):\n",
    "    s = data_all_final[i]\n",
    "    for j in range(len(ars_LM)):\n",
    "        ar = ars_LM[j]\n",
    "        if( re.search(rf'\\b{ar}\\b', s)):\n",
    "            s = re.sub(rf'\\b{ar}\\b',ens_LM[j],s)\n",
    "            found = True\n",
    "    \n",
    "    if(found):\n",
    "        data_all_final_filtered.append(s)\n",
    "        data_all_final_filtered_asle.append(data_all_final[i])\n",
    "        found = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"/home/mmaher/CS_Clean/d.txt\", \"w\")\n",
    "textfile.write(\"\\n*********************************************************************************************************************************************************************\\n\\n\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49db38fe42ca4de17a914e14764a291a8aeb5a2fabd7204247ace0962713e961"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('CS_VIR_ENV': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
