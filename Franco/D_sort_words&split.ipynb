{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data & words & sort words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 37 M lines\n",
    "with open('/home/mmaher/LM_CS/Franco/data_all_final.txt') as f:\n",
    "    lines = f.readlines()\n",
    "lines = list(set(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/mmaher/LM_CS/Franco/data/words_en_ar_after_filter_ALL.txt') as f:\n",
    "    words_ar_en = f.readlines()\n",
    "\n",
    "# Split to ar & en\n",
    "ars = [w.split(\"-->\")[0].replace(\"\\n\",\"\").strip() for w in words_ar_en]\n",
    "ens = [w.split(\"-->\")[1].replace(\"\\n\",\"\").strip() for w in words_ar_en]\n",
    "\n",
    "#sort by ar length\n",
    "ars_ens = dict(zip(ars,ens))\n",
    "ars_sorted = sorted(list(ars_ens.keys()), key=len, reverse=True)\n",
    "ens_sorted = [ars_ens[i] for i in ars_sorted]\n",
    "ars_ens_sorted = list(zip(ars_sorted,ens_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"/home/mmaher/LM_CS/Franco/data/words_en_ar_after_filter_ALL_sorted.txt\", \"w\")\n",
    "for i in ars_ens_sorted:\n",
    "    textfile.write(i[0] + \" --> \" + i[1] + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(file_pth, save_fold , tasks_num) :\n",
    "    \n",
    "    words = open(file_pth).readlines()\n",
    "    words_thr = int(len(words)/tasks_num)+1\n",
    "\n",
    "    #split words to files to be read by CPU\n",
    "    for i in range(tasks_num):\n",
    "        sub_words = words[i*words_thr : i*words_thr+words_thr ]\n",
    "        with open(os.path.join(save_fold,f'{str(i)}.txt'),\"w\") as f:\n",
    "            f.write(\"\".join(sub_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split(\"/home/mmaher/LM_CS/Franco/data/words_en_ar_after_filter_ALL_sorted.txt\", \"/home/mmaher/LM_CS/Franco/data/splits/\" , 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"/home/mmaher/LM_CS/Franco/data/splits_lines/\"\n",
    "ps = [p+i for i in os.listdir(p)]\n",
    "all_lines = []\n",
    "\n",
    "for i in ps:\n",
    "    with open(i) as f:\n",
    "        all_lines.extend(f.readlines())\n",
    "\n",
    "all_lines_en = []\n",
    "all_lines_ar = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(all_lines),6):\n",
    "    all_lines_ar.append((all_lines[i]))\n",
    "    all_lines_en.append((all_lines[i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"/home/mmaher/LM_CS/Franco/data/data_en_franco_all.txt\" , \"w\")\n",
    "\n",
    "for e in range(len(all_lines_en)):\n",
    "    textfile.write(all_lines_en[e])\n",
    "textfile.close()\n",
    "\n",
    "\n",
    "textfile = open(\"/home/mmaher/LM_CS/Franco/data/data_ar_franco_all.txt\" , \"w\")\n",
    "for e in range(len(all_lines_ar)):\n",
    "    textfile.write(all_lines_ar[e])\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"/home/mmaher/LM_CS/Franco/data_all_final.txt\"\n",
    "with open(p) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "line = list(set(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/36376916 [00:25<43469:24:10,  4.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48924/179586707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mlines_en_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lines_en_words = []\n",
    "for i in tqdm(range(len(line))):\n",
    "    l = line[i]\n",
    "    for j in l:\n",
    "        if(j.lower().strip() in words.words()):\n",
    "            lines_en_words.append(l)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1125476"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textfile = open(\"/home/mmaher/LM_CS/Franco/data/all_en.txt\" , \"w\")\n",
    "\n",
    "for e in range(len(data_all_final_filtered)):\n",
    "    textfile.write(data_all_final_filtered_asle[e])\n",
    "    textfile.write(data_all_final_filtered[e])\n",
    "    textfile.write(\"\\n*********************************************************************************************************************************************************************\\n\\n\\n\")\n",
    "textfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca2ea4dd711042ce916a1f350bb0af1ee06de2cd088216482cff3d6db9d14d59"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('LM_VENV': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
